{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvDf8yiv/P0OJ5+LV3rVKj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/purushottamk3112/call_analyzer/blob/main/Call_Quality_Analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4DnUrqUwO1D"
      },
      "outputs": [],
      "source": [
        "!pip -q install --upgrade yt-dlp pydub noisereduce pyannote.audio transformers torchaudio nltk --quiet\n",
        "!curl -L https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp -o /usr/local/bin/yt-dlp 2>/dev/null\n",
        "!chmod a+rx /usr/local/bin/yt-dlp\n",
        "\n",
        "# HF token\n",
        "from huggingface_hub import login\n",
        "login(\"\")  # your read-token\n",
        "\n",
        "import os, math, re, time, torch, numpy as np, pandas as pd\n",
        "from pydub import AudioSegment\n",
        "import noisereduce as nr\n",
        "from pyannote.audio import Pipeline\n",
        "from transformers import pipeline as hf_pipeline\n",
        "import nltk\n",
        "nltk.download('punkt', quiet=True)\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# Start timing\n",
        "start_time = time.time()\n",
        "\n",
        "# YouTube URL\n",
        "YOUTUBE_URL = \"https://youtu.be/4ostqJD3Psc?si=R0QZg6YjCPdmcR-2\"\n",
        "audio_path = \"/tmp/call.mp3\"\n",
        "\n",
        "# Download audio only (not video format 18)\n",
        "print(\"Downloading audio from YouTube...\")\n",
        "if os.path.exists(audio_path):\n",
        "    os.remove(audio_path)\n",
        "\n",
        "# Download best audio format and convert to mp3\n",
        "try:\n",
        "    os.system(f'yt-dlp -x --audio-format mp3 -o \"{audio_path}\" --quiet {YOUTUBE_URL}')\n",
        "except:\n",
        "    print(\"Primary download method failed, trying alternative...\")\n",
        "    os.system(f'yt-dlp -f bestaudio -o \"/tmp/call_temp.%(ext)s\" --quiet {YOUTUBE_URL}')\n",
        "    # Find the downloaded file\n",
        "    import glob\n",
        "    temp_files = glob.glob(\"/tmp/call_temp.*\")\n",
        "    if temp_files:\n",
        "        os.rename(temp_files[0], audio_path)\n",
        "\n",
        "if os.path.exists(audio_path):\n",
        "    print(f\"Downloaded → {audio_path} (Size: {os.path.getsize(audio_path)/1024:.1f} KB)\")\n",
        "else:\n",
        "    print(\"Error: Could not download audio. Please check the URL.\")\n",
        "    raise Exception(\"Download failed\")\n",
        "\n",
        "# Enhanced audio preprocessing for poor quality\n",
        "print(\"Processing audio...\")\n",
        "try:\n",
        "    raw = AudioSegment.from_file(audio_path)\n",
        "    raw = raw.set_frame_rate(16000).set_channels(1)\n",
        "\n",
        "    # Normalize audio\n",
        "    raw = raw.normalize()\n",
        "\n",
        "    # Convert to numpy array\n",
        "    sig = np.array(raw.get_array_of_samples(), dtype=np.float32)\n",
        "\n",
        "    # Normalize to [-1, 1] range\n",
        "    if np.max(np.abs(sig)) > 0:\n",
        "        sig = sig / np.max(np.abs(sig))\n",
        "\n",
        "    # Apply noise reduction with correct parameters\n",
        "    print(\"Applying noise reduction...\")\n",
        "    sig_cleaned = nr.reduce_noise(\n",
        "        y=sig,\n",
        "        sr=16000,\n",
        "        stationary=False,\n",
        "        prop_decrease=0.8  # Aggressive noise reduction\n",
        "    )\n",
        "\n",
        "    # Convert back to int16 for saving\n",
        "    sig_int16 = (sig_cleaned * 32767).astype(np.int16)\n",
        "\n",
        "    # Save cleaned audio\n",
        "    clean_path = \"/tmp/call_clean.wav\"\n",
        "    clean_audio = AudioSegment(\n",
        "        sig_int16.tobytes(),\n",
        "        frame_rate=16000,\n",
        "        sample_width=2,\n",
        "        channels=1\n",
        "    )\n",
        "    clean_audio.export(clean_path, format=\"wav\")\n",
        "    print(f\"Cleaned audio saved → {clean_path}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Audio processing error: {e}\")\n",
        "    print(\"Using original audio without noise reduction...\")\n",
        "    clean_path = audio_path\n",
        "\n",
        "# Speaker diarization with optimized parameters\n",
        "print(\"Performing speaker diarization...\")\n",
        "try:\n",
        "    dia_pipeline = Pipeline.from_pretrained(\n",
        "        \"pyannote/speaker-diarization-3.1\",\n",
        "        use_auth_token=True\n",
        "    )\n",
        "\n",
        "    if DEVICE.type == 'cuda':\n",
        "        dia_pipeline = dia_pipeline.to(DEVICE)\n",
        "\n",
        "    # Perform diarization\n",
        "    dia = dia_pipeline(\n",
        "        clean_path,\n",
        "        min_speakers=2,\n",
        "        max_speakers=2\n",
        "    )\n",
        "\n",
        "    # Calculate speaker durations\n",
        "    spk_dur = {}\n",
        "    speaker_segments = []\n",
        "    for turn, _, spk in dia.itertracks(yield_label=True):\n",
        "        duration = turn.end - turn.start\n",
        "        spk_dur[spk] = spk_dur.get(spk, 0.0) + duration\n",
        "        speaker_segments.append({\n",
        "            'speaker': spk,\n",
        "            'start': turn.start,\n",
        "            'end': turn.end,\n",
        "            'duration': duration\n",
        "        })\n",
        "\n",
        "    print(f\"Diarization completed: {len(speaker_segments)} segments found\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Diarization error: {e}\")\n",
        "    print(\"Using default speaker segments...\")\n",
        "    spk_dur = {\"SPEAKER_00\": 30.0, \"SPEAKER_01\": 30.0}\n",
        "    speaker_segments = [\n",
        "        {'speaker': 'SPEAKER_00', 'start': 0, 'end': 30, 'duration': 30},\n",
        "        {'speaker': 'SPEAKER_01', 'start': 30, 'end': 60, 'duration': 30}\n",
        "    ]\n",
        "    dia = None\n",
        "\n",
        "# Handle edge cases\n",
        "if not spk_dur:\n",
        "    print(\"Warning: No speakers detected, using defaults\")\n",
        "    spk_dur = {\"SPEAKER_00\": 30.0, \"SPEAKER_01\": 30.0}\n",
        "elif len(spk_dur) == 1:\n",
        "    only_spk = list(spk_dur.keys())[0]\n",
        "    other_spk = \"SPEAKER_01\" if only_spk == \"SPEAKER_00\" else \"SPEAKER_00\"\n",
        "    spk_dur[other_spk] = 0.1\n",
        "\n",
        "# Identify rep vs customer (longer speaker is likely the rep)\n",
        "rep_spk = max(spk_dur, key=spk_dur.get)\n",
        "cust_spk = [k for k in spk_dur if k != rep_spk][0]\n",
        "\n",
        "print(f\"Identified speakers: Rep={rep_spk} ({spk_dur[rep_spk]:.1f}s), Customer={cust_spk} ({spk_dur[cust_spk]:.1f}s)\")\n",
        "\n",
        "# Enhanced ASR with Whisper\n",
        "print(\"Transcribing audio with Whisper...\")\n",
        "try:\n",
        "    asr = hf_pipeline(\n",
        "        \"automatic-speech-recognition\",\n",
        "        model=\"openai/whisper-base\",\n",
        "        device=0 if DEVICE.type == 'cuda' else -1,\n",
        "        chunk_length_s=30,\n",
        "        batch_size=8\n",
        "    )\n",
        "\n",
        "    # Get transcription with timestamps\n",
        "    result = asr(\n",
        "        clean_path,\n",
        "        return_timestamps=\"word\",\n",
        "        generate_kwargs={\n",
        "            \"language\": \"en\",\n",
        "            \"task\": \"transcribe\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    words = result.get(\"chunks\", [])\n",
        "    full_text = result.get(\"text\", \"\")\n",
        "\n",
        "    # If word-level fails, try sentence-level\n",
        "    if not words or len(words) == 0:\n",
        "        print(\"Word-level timestamps not available, trying sentence-level...\")\n",
        "        result = asr(\n",
        "            clean_path,\n",
        "            return_timestamps=True,\n",
        "            generate_kwargs={\n",
        "                \"language\": \"en\",\n",
        "                \"task\": \"transcribe\"\n",
        "            }\n",
        "        )\n",
        "        words = result.get(\"chunks\", [])\n",
        "        full_text = result.get(\"text\", \"\")\n",
        "\n",
        "    print(f\"Transcribed {len(words)} segments\")\n",
        "    print(f\"Full transcript length: {len(full_text)} characters\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ASR error: {e}\")\n",
        "    words = []\n",
        "    full_text = \"Sample transcript for error case\"\n",
        "\n",
        "# Map words/segments to speakers\n",
        "utterances_raw = []\n",
        "\n",
        "if dia and words:  # Only if we have both diarization and transcription\n",
        "    for w in words:\n",
        "        if not w.get(\"timestamp\"):\n",
        "            continue\n",
        "\n",
        "        start, end = w[\"timestamp\"]\n",
        "        if start is None or end is None:\n",
        "            continue\n",
        "\n",
        "        text = w.get(\"text\", \"\").strip()\n",
        "        if not text:\n",
        "            continue\n",
        "\n",
        "        # Find which speaker this belongs to\n",
        "        mid = (start + end) / 2\n",
        "        assigned = False\n",
        "\n",
        "        for turn, _, spk in dia.itertracks(yield_label=True):\n",
        "            if turn.start <= mid <= turn.end:\n",
        "                utterances_raw.append({\n",
        "                    \"speaker\": \"Rep\" if spk == rep_spk else \"Customer\",\n",
        "                    \"text\": text,\n",
        "                    \"start\": start,\n",
        "                    \"end\": end,\n",
        "                    \"dur\": end - start\n",
        "                })\n",
        "                assigned = True\n",
        "                break\n",
        "\n",
        "        # If not assigned to any speaker, assign to closest\n",
        "        if not assigned and speaker_segments:\n",
        "            min_dist = float('inf')\n",
        "            closest_spk = rep_spk\n",
        "            for seg in speaker_segments:\n",
        "                dist = min(abs(mid - seg['start']), abs(mid - seg['end']))\n",
        "                if dist < min_dist:\n",
        "                    min_dist = dist\n",
        "                    closest_spk = seg['speaker']\n",
        "\n",
        "            utterances_raw.append({\n",
        "                \"speaker\": \"Rep\" if closest_spk == rep_spk else \"Customer\",\n",
        "                \"text\": text,\n",
        "                \"start\": start,\n",
        "                \"end\": end,\n",
        "                \"dur\": end - start\n",
        "            })\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(utterances_raw)\n",
        "\n",
        "# If no utterances detected, create from full text\n",
        "if len(df) == 0 and full_text:\n",
        "    print(\"No timestamped segments, analyzing full text...\")\n",
        "    sentences = sent_tokenize(full_text) if full_text else []\n",
        "    temp_data = []\n",
        "    for i, sent in enumerate(sentences[:50]):  # Limit to first 50 sentences\n",
        "        temp_data.append({\n",
        "            \"speaker\": \"Rep\" if i % 2 == 0 else \"Customer\",\n",
        "            \"text\": sent,\n",
        "            \"start\": i * 2,\n",
        "            \"end\": (i + 1) * 2,\n",
        "            \"dur\": 2\n",
        "        })\n",
        "    df = pd.DataFrame(temp_data)\n",
        "\n",
        "# Fallback if still empty\n",
        "if len(df) == 0:\n",
        "    df = pd.DataFrame([\n",
        "        {\"speaker\": \"Rep\", \"text\": \"Sample rep text\", \"start\": 0, \"end\": 10, \"dur\": 10},\n",
        "        {\"speaker\": \"Customer\", \"text\": \"Sample customer text\", \"start\": 10, \"end\": 20, \"dur\": 10}\n",
        "    ])\n",
        "\n",
        "print(f\"Created {len(df)} utterance records\")\n",
        "\n",
        "# Enhanced speaker identification using keywords\n",
        "sales_keywords = [\n",
        "    r'\\b(product|service|offer|demo|trial|team|sales|company|solution|feature|pricing)\\b',\n",
        "    r'\\b(we offer|we provide|we have|our customers|our platform)\\b',\n",
        "    r'\\b(let me show|let me explain|I can help)\\b'\n",
        "]\n",
        "\n",
        "customer_keywords = [\n",
        "    r'\\b(I need|I want|looking for|we need|we want)\\b',\n",
        "    r'\\b(my business|my company|our budget|our requirements)\\b',\n",
        "    r'\\b(how much|cost|pricing|budget)\\b'\n",
        "]\n",
        "\n",
        "# Check utterances for keywords\n",
        "if len(df) > 0:\n",
        "    first_utterances = df.head(min(10, len(df)))\n",
        "    rep_score = 0\n",
        "    cust_score = 0\n",
        "\n",
        "    for _, row in first_utterances.iterrows():\n",
        "        text_lower = row['text'].lower()\n",
        "        speaker = row['speaker']\n",
        "\n",
        "        # Check sales keywords\n",
        "        for pattern in sales_keywords:\n",
        "            if re.search(pattern, text_lower, re.I):\n",
        "                if speaker == \"Rep\":\n",
        "                    rep_score += 1\n",
        "                else:\n",
        "                    cust_score += 1\n",
        "\n",
        "        # Check customer keywords\n",
        "        for pattern in customer_keywords:\n",
        "            if re.search(pattern, text_lower, re.I):\n",
        "                if speaker == \"Customer\":\n",
        "                    rep_score += 1\n",
        "                else:\n",
        "                    cust_score += 1\n",
        "\n",
        "    # Swap labels if keywords suggest misidentification\n",
        "    if cust_score > rep_score + 2:\n",
        "        print(\"Swapping speaker labels based on keyword analysis...\")\n",
        "        df['speaker'] = df['speaker'].map({'Rep': 'Customer', 'Customer': 'Rep'})\n",
        "\n",
        "# Group consecutive utterances by same speaker\n",
        "df['group'] = (df['speaker'] != df['speaker'].shift()).cumsum()\n",
        "utterances = df.groupby('group').agg({\n",
        "    'speaker': 'first',\n",
        "    'text': lambda x: ' '.join(x),\n",
        "    'start': 'min',\n",
        "    'end': 'max',\n",
        "    'dur': 'sum'\n",
        "}).reset_index(drop=True)\n",
        "\n",
        "print(f\"Grouped into {len(utterances)} conversation turns\")\n",
        "\n",
        "# Calculate KPIs\n",
        "\n",
        "# 1. Talk-time ratio\n",
        "total_rep = df[df.speaker == \"Rep\"].dur.sum() if len(df) > 0 else 0\n",
        "total_cust = df[df.speaker == \"Customer\"].dur.sum() if len(df) > 0 else 0\n",
        "total_time = total_rep + total_cust\n",
        "\n",
        "if total_time > 0:\n",
        "    rep_ratio = (total_rep / total_time * 100)\n",
        "    cust_ratio = (total_cust / total_time * 100)\n",
        "else:\n",
        "    # Use diarization data as fallback\n",
        "    total_rep = spk_dur.get(rep_spk, 30)\n",
        "    total_cust = spk_dur.get(cust_spk, 30)\n",
        "    total_time = total_rep + total_cust\n",
        "    rep_ratio = (total_rep / total_time * 100)\n",
        "    cust_ratio = (total_cust / total_time * 100)\n",
        "\n",
        "# 2. Enhanced question detection\n",
        "question_patterns = [\n",
        "    r'\\?',  # Question mark\n",
        "    r'\\b(do|does|did|can|could|would|will|shall|should|is|are|was|were|have|has|had)\\s+\\w+',  # Auxiliary verbs\n",
        "    r'\\b(what|when|where|who|whom|whose|which|why|how)\\b',  # WH-questions\n",
        "    r'\\b(right|correct|isn\\'t it|don\\'t you think|agree)\\s*\\??',  # Tag questions\n",
        "    r'\\b(tell me|explain|describe|clarify)\\b',  # Indirect questions\n",
        "]\n",
        "\n",
        "# Count questions\n",
        "n_questions = 0\n",
        "question_texts = []\n",
        "\n",
        "if len(utterances) > 0:\n",
        "    for _, row in utterances.iterrows():\n",
        "        text = row['text']\n",
        "        # Check each pattern\n",
        "        for pattern in question_patterns:\n",
        "            if re.search(pattern, text, re.IGNORECASE):\n",
        "                n_questions += 1\n",
        "                question_texts.append(text[:60] + \"...\" if len(text) > 60 else text)\n",
        "                break  # Count each utterance only once\n",
        "\n",
        "print(f\"Detected {n_questions} questions\")\n",
        "\n",
        "# 3. Longest monologue from diarization\n",
        "longest_monologue = 0.0\n",
        "longest_speaker = None\n",
        "\n",
        "if speaker_segments:\n",
        "    for seg in speaker_segments:\n",
        "        if seg['duration'] > longest_monologue:\n",
        "            longest_monologue = seg['duration']\n",
        "            longest_speaker = \"Rep\" if seg['speaker'] == rep_spk else \"Customer\"\n",
        "\n",
        "# 4. Sentiment analysis\n",
        "print(\"Analyzing sentiment...\")\n",
        "try:\n",
        "    sent_analyzer = hf_pipeline(\n",
        "        \"sentiment-analysis\",\n",
        "        model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
        "        device=0 if DEVICE.type == 'cuda' else -1\n",
        "    )\n",
        "\n",
        "    # Prepare text for sentiment analysis\n",
        "    rep_text = \" \".join(utterances[utterances.speaker == \"Rep\"].text.tolist()) if len(utterances) > 0 else \"\"\n",
        "    cust_text = \" \".join(utterances[utterances.speaker == \"Customer\"].text.tolist()) if len(utterances) > 0 else \"\"\n",
        "\n",
        "    def analyze_sentiment(text, label=\"\"):\n",
        "        if not text or len(text.strip()) < 10:\n",
        "            return \"neutral\", 0.5\n",
        "\n",
        "        # Take first 500 characters for sentiment\n",
        "        text_sample = text[:500]\n",
        "\n",
        "        try:\n",
        "            result = sent_analyzer(text_sample)[0]\n",
        "            label = result['label'].lower()\n",
        "            score = result['score']\n",
        "\n",
        "            if label == 'positive' and score > 0.7:\n",
        "                return \"positive\", score\n",
        "            elif label == 'negative' and score > 0.7:\n",
        "                return \"negative\", score\n",
        "            else:\n",
        "                return \"neutral\", 0.5\n",
        "        except:\n",
        "            return \"neutral\", 0.5\n",
        "\n",
        "    # Analyze sentiment for each speaker\n",
        "    rep_sent, rep_score = analyze_sentiment(rep_text, \"Rep\")\n",
        "    cust_sent, cust_score = analyze_sentiment(cust_text, \"Customer\")\n",
        "\n",
        "    # Overall sentiment (weighted average)\n",
        "    if total_time > 0:\n",
        "        overall_score = (rep_score * total_rep + cust_score * total_cust) / total_time\n",
        "    else:\n",
        "        overall_score = (rep_score + cust_score) / 2\n",
        "\n",
        "    if overall_score > 0.6:\n",
        "        overall_sent = \"positive\"\n",
        "    elif overall_score < 0.4:\n",
        "        overall_sent = \"negative\"\n",
        "    else:\n",
        "        overall_sent = \"neutral\"\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Sentiment analysis error: {e}\")\n",
        "    rep_sent, rep_score = \"neutral\", 0.5\n",
        "    cust_sent, cust_score = \"neutral\", 0.5\n",
        "    overall_sent, overall_score = \"neutral\", 0.5\n",
        "\n",
        "print(f\"Sentiment - Rep: {rep_sent}, Customer: {cust_sent}, Overall: {overall_sent}\")\n",
        "\n",
        "# 5. Generate actionable insight\n",
        "insights = []\n",
        "\n",
        "# Talk-time balance insight\n",
        "if rep_ratio > 70:\n",
        "    insights.append(f\"Rep dominated with {rep_ratio:.0f}% talk-time. Focus on customer discovery.\")\n",
        "elif cust_ratio > 70:\n",
        "    insights.append(f\"Customer spoke {cust_ratio:.0f}% of time. Rep should provide more guidance.\")\n",
        "elif 45 <= rep_ratio <= 55:\n",
        "    insights.append(\"Good talk-time balance achieved.\")\n",
        "\n",
        "# Questions insight\n",
        "if n_questions < 3:\n",
        "    insights.append(f\"Only {n_questions} questions detected. Use more discovery questions.\")\n",
        "elif n_questions > 15:\n",
        "    insights.append(f\"{n_questions} questions asked. Good discovery happening.\")\n",
        "\n",
        "# Monologue insight\n",
        "if longest_monologue > 60:\n",
        "    insights.append(f\"{longest_monologue:.0f}s monologue detected. Break up with checks.\")\n",
        "\n",
        "# Sentiment insight\n",
        "if overall_sent == \"negative\":\n",
        "    insights.append(\"Negative sentiment. Address concerns and build rapport.\")\n",
        "elif overall_sent == \"positive\":\n",
        "    insights.append(\"Positive sentiment. Good time to advance the conversation.\")\n",
        "\n",
        "# Select primary insight\n",
        "if insights:\n",
        "    actionable_insight = \" \".join(insights[:2])  # Combine top 2 insights\n",
        "else:\n",
        "    actionable_insight = \"Continue monitoring call metrics for improvements.\"\n",
        "\n",
        "# Create final report\n",
        "report = pd.DataFrame({\n",
        "    \"Metric\": [\n",
        "        \"Rep talk-time %\",\n",
        "        \"Customer talk-time %\",\n",
        "        \"Questions asked\",\n",
        "        \"Longest monologue (s)\",\n",
        "        \"Rep sentiment\",\n",
        "        \"Customer sentiment\",\n",
        "        \"Overall sentiment\",\n",
        "        \"Actionable insight\"\n",
        "    ],\n",
        "    \"Value\": [\n",
        "        f\"{rep_ratio:.1f}%\",\n",
        "        f\"{cust_ratio:.1f}%\",\n",
        "        n_questions,\n",
        "        f\"{longest_monologue:.1f}s\",\n",
        "        f\"{rep_sent}\",\n",
        "        f\"{cust_sent}\",\n",
        "        f\"{overall_sent}\",\n",
        "        actionable_insight\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Display results\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"         CALL QUALITY ANALYSIS REPORT\")\n",
        "print(\"=\"*60)\n",
        "print(report.to_string(index=False))\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Additional statistics\n",
        "print(f\"\\nProcessing Statistics:\")\n",
        "print(f\"• Total call duration: {total_time:.1f} seconds\")\n",
        "print(f\"• Total utterances: {len(utterances)}\")\n",
        "print(f\"• Processing time: {time.time() - start_time:.1f} seconds\")\n",
        "\n",
        "# Save transcript\n",
        "try:\n",
        "    transcript_path = \"/tmp/call_transcript.txt\"\n",
        "    with open(transcript_path, 'w') as f:\n",
        "        f.write(\"CALL TRANSCRIPT\\n\")\n",
        "        f.write(\"=\"*50 + \"\\n\\n\")\n",
        "        for _, row in utterances.iterrows():\n",
        "            f.write(f\"[{row['speaker']}]: {row['text']}\\n\\n\")\n",
        "    print(f\"• Transcript saved to: {transcript_path}\")\n",
        "except:\n",
        "    print(\"• Could not save transcript\")\n",
        "\n",
        "print(\"\\nAnalysis complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GKNRQkFowbz8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}